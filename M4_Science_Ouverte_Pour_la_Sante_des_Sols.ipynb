{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeQE1M5QXgZ2"
   },
   "source": [
    "**Cartographie Haute Résolution du Carbone Organique du Sol (Algérie)**\n",
    "\n",
    "Instructeur : Dr. Ghiles Kaci\n",
    "\n",
    "Durée : 2 Heures\n",
    "\n",
    "Zone Géographique : Atlas Tellien, Algérie\n",
    "\n",
    "**1. Introduction et Objectifs d'Apprentissage**\n",
    "\n",
    "**Le Défi :**\n",
    "Les cartes mondiales des sols (comme SoilGrids) sont excellentes, mais elles sont souvent trop grossières (résolution de 250m) pour la prise de décision agricole locale. Les agriculteurs gèrent leurs terres à l'échelle de mètres, pas de centaines de mètres.\n",
    "\n",
    "**La Solution :**\n",
    "Nous pouvons effectuer un « downscaling » (réduction d'échelle) de ces cartes grossières en les fusionnant avec des données satellitaires à haute résolution. Nous utilisons la carte grossière comme « enseignant » (données d'entraînement) et les satellites à haute résolution (Landsat, SRTM) comme « prédicteurs » pour générer une nouvelle carte détaillée à 30m.\n",
    "\n",
    "**Objectifs d'Apprentissage :**\n",
    "\n",
    "\n",
    "\n",
    "*   **Accéder** aux données géospatiales cloud-natives (Landsat, SRTM) et aux données locales des sols.\n",
    "*   **Calculer** des indices environnementaux (MSAVI, Indice de Sol Nu) pour représenter la végétation et la santé des sols.\n",
    "*   **Construire** un jeu de données d'entraînement par rééchantillonnage et alignement de rasters disparates (Downscaling).\n",
    "*   **Entraîner** un régresseur Random Forest pour prédire le Carbone Organique du Sol (COS).\n",
    "*   **Quantifier** l'incertitude du modèle en utilisant une approche d'ensemble.\n",
    "\n",
    "**2. Configuration et Bibliothèques**\n",
    "\n",
    "Nous nous appuyons sur la pile Pangeo — un écosystème moderne d'outils open source pour les grandes données géospatiales.\n",
    "\n",
    "1. xarray / rioxarray : Pour manipuler les données raster multidimensionnelles (tableaux étiquetés).\n",
    "\n",
    "2. pystac_client : Pour rechercher dans les catalogues satellites comme Google.\n",
    "\n",
    "3. scikit-learn : Pour le modèle d'apprentissage automatique Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qijGVKZgIw0H",
    "outputId": "f97830eb-4668-44e7-ce67-f806f25f4f97"
   },
   "outputs": [],
   "source": [
    "# Installer les packages nécessaires (décommenter si exécution dans Colab/Binder)\n",
    "!pip install pystac-client planetary-computer rioxarray xarray geopandas rasterio scikit-learn matplotlib\n",
    "\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Configurer matplotlib pour de jolis graphiques\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxHZthYhYJPH"
   },
   "source": [
    "**3. Acquisition des Données**\n",
    "\n",
    "**3.1 Définir la Zone d'Intérêt (ZI)**\n",
    "\n",
    "Pour assurer une exécution fluide sur vos ordinateurs portables, nous allons nous concentrer sur une fenêtre agricole spécifique dans la région de l'Atlas Tellien du nord de l'Algérie. Nous définissons cela en utilisant une Boîte Englobante (Bounding Box)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-H-8hYEIz3H",
    "outputId": "90ea1de8-8b45-4f2e-ad0a-53a3ff8cb37d"
   },
   "outputs": [],
   "source": [
    "# Définir la Zone d'Intérêt (Atlas Tellien, Algérie)\n",
    "# Format : [lon_min, lat_min, lon_max, lat_max]\n",
    "# Ceci couvre une zone d'environ 10km x 10km pour assurer un traitement rapide\n",
    "aoi_bbox = [3.0, 36.4, 3.15, 36.5]\n",
    "\n",
    "print(f\"Zone d'étude définie : {aoi_bbox}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLH2MWZaYhFB"
   },
   "source": [
    "**3.2 Accéder à la Variable Cible (SoilGrids)**\n",
    "\n",
    "Nous utilisons **SoilGrids (ISRIC)** comme notre « Pseudo-Vérité Terrain ». Nous nous intéressons au stock de COS (0-5cm).\n",
    "\n",
    "**Gestion de l'Accès aux Données :**\n",
    "Nous allons charger le fichier local out.tif qui contient les données SoilGrids. Le code ci-dessous est robuste : il vérifie à la fois votre dossier actuel (si vous l'avez téléchargé) et votre chemin Windows local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "Qwa2T04JI4oi",
    "outputId": "9d46deb5-a0c9-4d89-dfb7-4e6b5a9e6aa6"
   },
   "outputs": [],
   "source": [
    "# Définir le nom du fichier\n",
    "target_file = \"out.tif\"\n",
    "\n",
    "# Liste des chemins à vérifier\n",
    "# 1. Vérifier le répertoire actuel (par défaut pour les téléchargements Colab/Cloud)\n",
    "# 2. Vérifier votre chemin Windows local spécifique (si exécution locale)\n",
    "possible_paths = [\n",
    "    target_file,\n",
    "    r\"C:\\Users\\ghile\\Downloads\\out.tif\"\n",
    "]\n",
    "\n",
    "local_filepath = None\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        local_filepath = path\n",
    "        print(f\"Succès ! Fichier trouvé à : {local_filepath}\")\n",
    "        break\n",
    "\n",
    "if local_filepath is None:\n",
    "    # Informations de débogage si le fichier est manquant\n",
    "    print(f\"\\nERREUR : Impossible de trouver '{target_file}' dans ces emplacements :\")\n",
    "    for p in possible_paths:\n",
    "        print(f\" - {p}\")\n",
    "    print(f\"\\nRépertoire de travail actuel : {os.getcwd()}\")\n",
    "    try:\n",
    "        print(f\"Fichiers disponibles ici : {os.listdir()}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    raise FileNotFoundError(\"Veuillez télécharger 'out.tif' dans l'environnement de ce notebook (onglet Fichiers à gauche).\")\n",
    "\n",
    "# Ouvrir le fichier trouvé\n",
    "soc_coarse = rioxarray.open_rasterio(local_filepath)\n",
    "\n",
    "# --- POST-TRAITEMENT ---\n",
    "# Découper selon la ZI (Vérification de sécurité)\n",
    "soc_coarse = soc_coarse.rio.clip_box(*aoi_bbox)\n",
    "\n",
    "# Renommer en 'soc' et sauvegarder en mémoire\n",
    "soc_coarse.name = \"soc\"\n",
    "\n",
    "# Visualiser la « Vérité »\n",
    "soc_coarse.plot(cmap=\"magma\")\n",
    "plt.title(\"Cible : Stock COS Grossier (0-5cm) [SoilGrids 250m]\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Résolution COS originale :\", soc_coarse.rio.resolution())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzCm0sHzZ4D2"
   },
   "source": [
    "**3.3 Accéder aux Prédicteurs : Relief (Topographie)**\n",
    "\n",
    "La topographie contrôle l'écoulement de l'eau et l'accumulation des sols. Nous utilisons le **NASADEM (SRTM)** à résolution 30m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "id": "i5hc6rZOI8Aa",
    "outputId": "0c4c4ce3-27f0-4e25-bceb-152045671602"
   },
   "outputs": [],
   "source": [
    "# Se connecter au Catalogue STAC de Microsoft Planetary Computer\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "\n",
    "# Rechercher les Données d'Élévation\n",
    "search = catalog.search(\n",
    "    collections=[\"nasadem\"],\n",
    "    bbox=aoi_bbox\n",
    ")\n",
    "item = next(search.items()) # Obtenir la première tuile disponible\n",
    "\n",
    "# Charger l'Élévation\n",
    "elevation = rioxarray.open_rasterio(item.assets[\"elevation\"].href)\n",
    "elevation = elevation.rio.clip_box(*aoi_bbox)\n",
    "# Supprimer la dimension 'band', car nous travaillons généralement avec une seule bande pour l'élévation\n",
    "elevation = elevation.squeeze('band', drop=True)\n",
    "\n",
    "# Calculer la Pente (Gradient numérique simplifié)\n",
    "# Dans un flux de production complet, nous utiliserions xarray-spatial pour cela\n",
    "# Maintenant elevation.values est 2D, et elevation.coords/dims sont 2D\n",
    "dx, dy = np.gradient(elevation.values)\n",
    "slope = np.sqrt(dx**2 + dy**2)\n",
    "slope_da = xr.DataArray(slope, coords=elevation.coords, dims=elevation.dims)\n",
    "slope_da.name = \"slope\"\n",
    "\n",
    "# Afficher\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "elevation.plot(ax=ax1, cmap=\"terrain\")\n",
    "ax1.set_title(\"Élévation (m)\")\n",
    "slope_da.plot(ax=ax2, cmap=\"Greys\")\n",
    "ax2.set_title(\"Gradient de Pente\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORqwKg_SaE1T"
   },
   "source": [
    "**3.4 Accéder aux Prédicteurs : Imagerie Satellitaire (Landsat)**\n",
    "\n",
    "Nous utilisons les bandes Landsat pour dériver des indices de végétation et de sol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "o-bVwFf9I_Ay",
    "outputId": "d31db2fd-ad6b-4498-c3e5-ee94b1d93f10"
   },
   "outputs": [],
   "source": [
    "# Rechercher Landsat Collection 2 Niveau-2 (Réflectance de Surface)\n",
    "search_landsat = catalog.search(\n",
    "    collections=[\"landsat-c2-l2\"],\n",
    "    bbox=aoi_bbox,\n",
    "    # Plage de dates large (Printemps/Été 2023-2024) pour trouver de bonnes données\n",
    "    datetime=\"2023-01-01/2024-12-31\",\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 20}} # Assoupli à 20% pour s'assurer de trouver une scène\n",
    ")\n",
    "\n",
    "# Obtenir tous les éléments trouvés et trier par couverture nuageuse (moins nuageux en premier)\n",
    "landsat_items = sorted(list(search_landsat.items()), key=lambda item: item.properties[\"eo:cloud_cover\"])\n",
    "\n",
    "print(f\"{len(landsat_items)} scènes Landsat potentielles trouvées.\")\n",
    "\n",
    "if not landsat_items:\n",
    "    raise ValueError(\"Aucune scène Landsat trouvée. Essayez d'augmenter le seuil de couverture nuageuse ou d'élargir la plage de dates.\")\n",
    "\n",
    "# Essayer de trouver une scène qui couvre complètement notre ZI\n",
    "selected_item = None\n",
    "bands = {}\n",
    "required_bands = [\"red\", \"blue\", \"nir08\", \"swir16\"]\n",
    "\n",
    "print(\"Vérification des scènes pour une couverture complète...\")\n",
    "for item in landsat_items:\n",
    "    try:\n",
    "        current_bands = {}\n",
    "        # Essayer de charger toutes les bandes requises\n",
    "        for band in required_bands:\n",
    "            da = rioxarray.open_rasterio(item.assets[band].href)\n",
    "\n",
    "            # --- CORRECTION CRITIQUE ---\n",
    "            # Les données Landsat sont en UTM (mètres), mais notre bbox est en Lat/Lon (degrés).\n",
    "            # Nous DEVONS indiquer à clip_box que nos coordonnées sont EPSG:4326 pour qu'il puisse les transformer.\n",
    "            clipped_da = da.rio.clip_box(*aoi_bbox, crs=\"EPSG:4326\")\n",
    "\n",
    "            # Vérifier si des données valides existent (pas seulement des pixels nodata vides)\n",
    "            if clipped_da.count() == 0:\n",
    "                # Cela peut arriver si la boîte reprojetée tombe en dehors des limites de l'image\n",
    "                raise ValueError(\"Données vides après découpage\")\n",
    "\n",
    "            current_bands[band] = clipped_da\n",
    "\n",
    "        # Si nous arrivons ici, toutes les bandes ont été chargées et découpées avec succès\n",
    "        selected_item = item\n",
    "        bands = current_bands\n",
    "        print(f\"Scène sélectionnée : {selected_item.id} | Couverture nuageuse : {selected_item.properties['eo:cloud_cover']}%\")\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        # Si une bande échoue (ex. ZI au bord de la scène), passer à l'élément suivant\n",
    "        continue\n",
    "\n",
    "if selected_item is None:\n",
    "    raise ValueError(\"Impossible de trouver une scène unique couvrant entièrement la ZI. Veuillez ajuster les coordonnées de la ZI.\")\n",
    "\n",
    "# --- CALCULER LES INDICES ---\n",
    "\n",
    "# 1. Formule MSAVI : (2 * NIR + 1 - sqrt((2 * NIR + 1)^2 - 8 * (NIR - Red))) / 2\n",
    "# Note : Utiliser les valeurs DN brutes pour les indices basés sur des ratios est une simplification courante en enseignement.\n",
    "# Idéalement, appliquer les facteurs d'échelle (0.0000275 + -0.2) pour les valeurs physiques.\n",
    "nir = bands[\"nir08\"].astype(float)\n",
    "red = bands[\"red\"].astype(float)\n",
    "blue = bands[\"blue\"].astype(float)\n",
    "swir = bands[\"swir16\"].astype(float)\n",
    "\n",
    "msavi = (2 * nir + 1 - np.sqrt((2 * nir + 1)**2 - 8 * (nir - red))) / 2\n",
    "msavi.name = \"msavi\"\n",
    "\n",
    "# 2. Indice de Sol Nu (BSI)\n",
    "# Formule : ((Rouge + SWIR) - (NIR + Bleu)) / ((Rouge + SWIR) + (NIR + Bleu))\n",
    "bsi = ((red + swir) - (nir + blue)) / ((red + swir) + (nir + blue))\n",
    "bsi.name = \"bsi\"\n",
    "\n",
    "# Visualiser\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "msavi.plot(ax=ax1, cmap=\"YlGn\", vmin=-1, vmax=1)\n",
    "ax1.set_title(\"MSAVI (Végétation)\")\n",
    "bsi.plot(ax=ax2, cmap=\"copper_r\", vmin=-1, vmax=1)\n",
    "ax2.set_title(\"BSI (Sol Nu)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmWd_kAQaTmM"
   },
   "source": [
    "**4. Ingénierie des Données (La « Magie » du Downscaling)**\n",
    "\n",
    "C'est l'étape technique la plus critique. Nous avons :\n",
    "\n",
    "1. **Cible :** COS à 250m.\n",
    "\n",
    "2. **Prédicteurs :** Élévation/Landsat à 30m.\n",
    "\n",
    "Nous devons aligner tout sur la grille 30m. Cela « étale » effectivement les données de sol grossières sur la grille fine, permettant au modèle d'apprentissage automatique d'apprendre la relation entre le motif de sol grossier et les détails environnementaux fins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYJvK8xPJB0Z",
    "outputId": "cc47c19d-aaa7-4f2c-8d09-99ffc9b05630"
   },
   "outputs": [],
   "source": [
    "# 1. Définir la Grille Maître (La grille Landsat 30m)\n",
    "master_grid = msavi\n",
    "\n",
    "# 2. Reprojeter et Rééchantillonner Tout pour Correspondre à la Grille Maître\n",
    "# Nous utilisons 'nearest' pour la cible pour préserver les valeurs originales sans lissage\n",
    "soc_aligned = soc_coarse.rio.reproject_match(master_grid, resampling=1) # 1=Plus proche voisin\n",
    "elevation_aligned = elevation.rio.reproject_match(master_grid)\n",
    "slope_aligned = slope_da.rio.reproject_match(master_grid)\n",
    "\n",
    "print(f\"Forme et NaN pour les données alignées avant empilement :\")\n",
    "print(f\"  soc_aligned : forme={soc_aligned.shape}, NaN={soc_aligned.isnull().sum().item()}\")\n",
    "print(f\"  elevation_aligned : forme={elevation_aligned.shape}, NaN={elevation_aligned.isnull().sum().item()}\")\n",
    "print(f\"  slope_aligned : forme={slope_aligned.shape}, NaN={slope_aligned.isnull().sum().item()}\")\n",
    "print(f\"  msavi (maître) : forme={msavi.shape}, NaN={msavi.isnull().sum().item()}\")\n",
    "print(f\"  bsi : forme={bsi.shape}, NaN={bsi.isnull().sum().item()}\")\n",
    "\n",
    "\n",
    "# 3. Empiler tous les Prédicteurs dans un « Cube »\n",
    "# Note : Nous utilisons squeeze() pour supprimer la dimension 'band' qui a généralement une taille de 1\n",
    "stack = xr.merge([\n",
    "    msavi.rename(\"msavi\").squeeze(),\n",
    "    bsi.rename(\"bsi\").squeeze(),\n",
    "    elevation_aligned.rename(\"elevation\").squeeze(),\n",
    "    slope_aligned.rename(\"slope\").squeeze()\n",
    "])\n",
    "\n",
    "# Ajouter la Cible (COS) à la pile\n",
    "stack[\"soc\"] = soc_aligned.squeeze()\n",
    "\n",
    "print(f\"\\nForme de la pile après fusion (avant filtre COS) : {stack.dims}\")\n",
    "print(\"NaN par variable dans la pile (avant filtre COS) :\")\n",
    "for var_name in stack.data_vars:\n",
    "    print(f\"  {var_name} : {stack[var_name].isnull().sum().item()}\")\n",
    "\n",
    "# 4. Masquer les NaN (pixels avec données manquantes) plus soigneusement\n",
    "original_total_pixels = stack.soc.size\n",
    "# Filtrer les pixels où COS est <= 0 (valeurs invalides)\n",
    "stack = stack.where(stack[\"soc\"] > 0)\n",
    "pixels_after_soc_filter = stack.soc.notnull().sum().item()\n",
    "print(f\"\\nPixels avec COS > 0 après filtre : {pixels_after_soc_filter} sur {original_total_pixels}\")\n",
    "\n",
    "# Convertir en DataFrame, puis dropna uniquement pour la colonne 'soc' pour les données d'entraînement\n",
    "# Cela garantit que nous conservons les pixels pour lesquels nous avons une valeur cible valide,\n",
    "# même si certaines variables prédictives peuvent avoir des NaN (que Random Forest peut gérer)\n",
    "# Nous utiliserons ce df directement dans la cellule suivante.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2as2thxaeO0"
   },
   "source": [
    "**5. Créer les Données d'Entraînement (Pseudo-Vérité Terrain)**\n",
    "\n",
    "Nous ne pouvons pas alimenter directement une image dans un Random Forest standard. Nous avons besoin d'une **Table** (DataFrame).\n",
    "Nous allons échantillonner aléatoirement 10 000 points de notre pile alignée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_CGtcCQJEqc",
    "outputId": "e7132782-9080-4e52-8062-959e8943883a"
   },
   "outputs": [],
   "source": [
    "# Convertir le Dataset xarray en DataFrame Pandas\n",
    "# Cela aplatit la carte en une table de pixels\n",
    "df = stack.to_dataframe().reset_index()\n",
    "\n",
    "# Supprimer explicitement les lignes où la variable cible 'soc' est NaN\n",
    "df = df.dropna(subset=[\"soc\"])\n",
    "\n",
    "# Supprimer également les pixels où msavi, bsi, elevation ou slope sont NaN, car ce sont des caractéristiques\n",
    "df = df.dropna(subset=[\"msavi\", \"bsi\", \"elevation\", \"slope\"])\n",
    "\n",
    "print(f\"Total de pixels disponibles après nettoyage : {len(df)}\")\n",
    "\n",
    "# Échantillonner 10 000 pixels aléatoires pour l'entraînement\n",
    "# Nous utilisons un sous-ensemble pour simuler l'échantillonnage de terrain et accélérer l'entraînement\n",
    "# S'assurer de ne pas essayer d'échantillonner plus que les pixels disponibles\n",
    "sample_size = min(10000, len(df))\n",
    "if sample_size == 0:\n",
    "    raise ValueError(\"Aucun pixel valide disponible après nettoyage. Impossible de procéder à l'échantillonnage.\")\n",
    "training_data = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "print(\"En-tête de la Table d'Entraînement :\")\n",
    "print(training_data[[\"soc\", \"msavi\", \"bsi\", \"slope\"]].head())\n",
    "\n",
    "# Division Caractéristiques/Cible\n",
    "X = training_data[[\"msavi\", \"bsi\", \"elevation\", \"slope\"]]\n",
    "y = training_data[\"soc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5mFGWVSan3u"
   },
   "source": [
    "**6. Modélisation : Régresseur Random Forest**\n",
    "\n",
    "Nous utilisons l'algorithme Random Forest car il gère bien les relations non linéaires (ex. le COS augmente avec la végétation mais pourrait diminuer si les pentes deviennent trop raides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "f89092a1",
    "outputId": "1e161cbe-fd7c-4030-efad-a32adab0c703"
   },
   "outputs": [],
   "source": [
    "# Diviser en ensembles d'Entraînement et de Validation (80% entraînement, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser le Modèle\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Entraîner le Modèle\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Valider\n",
    "predictions = rf_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"Performance du Modèle :\")\n",
    "print(f\"RMSE : {rmse:.2f} (Mg C/ha)\")\n",
    "print(f\"R-Carré : {r2:.2f}\")\n",
    "\n",
    "# Graphique d'Importance des Caractéristiques\n",
    "importances = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
    "importances.sort_values().plot(kind='barh', color='teal')\n",
    "plt.title(\"Qu'est-ce qui détermine le COS en Algérie ?\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "py1DxU-0aq8d"
   },
   "source": [
    "**7. Cartographie Opérationnelle et Incertitude**\n",
    "\n",
    "Nous allons maintenant appliquer notre « cerveau » entraîné (le modèle) à toute la zone d'étude (tous les pixels, pas seulement ceux d'entraînement).\n",
    "Pour quantifier la confiance, nous allons exécuter un petit **Ensemble** : nous prédisons 10 fois, et vérifions où les prédictions concordent (stable) ou divergent (incertain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLNLVCVgJHaC",
    "outputId": "2f8f8f19-1e30-48a7-dca9-cf97d49f8ad7"
   },
   "outputs": [],
   "source": [
    "# Préparer les données d'entrée complètes pour la prédiction\n",
    "# Nous devons supprimer la colonne 'soc' et les colonnes de coordonnées\n",
    "full_input = df[[\"msavi\", \"bsi\", \"elevation\", \"slope\"]]\n",
    "\n",
    "# --- PRÉDICTION D'ENSEMBLE ---\n",
    "n_iterations = 10\n",
    "all_predictions = []\n",
    "\n",
    "print(\"Exécution de la Boucle de Prédiction d'Ensemble...\")\n",
    "for i in range(n_iterations):\n",
    "    # Entraîner un nouveau modèle avec une graine aléatoire différente\n",
    "    model = RandomForestRegressor(n_estimators=25, random_state=i, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Prédire sur la zone COMPLÈTE\n",
    "    pred = model.predict(full_input)\n",
    "    all_predictions.append(pred)\n",
    "\n",
    "# Convertir la liste de tableaux en tableau numpy\n",
    "all_predictions = np.array(all_predictions) # Forme : (10, num_pixels)\n",
    "\n",
    "# Calculer la Moyenne (La Carte Finale) et l'Écart-Type (La Carte d'Incertitude)\n",
    "mean_pred = np.mean(all_predictions, axis=0)\n",
    "std_pred = np.std(all_predictions, axis=0)\n",
    "\n",
    "# Remettre dans le dataframe pour reconstruire la carte\n",
    "df[\"soc_predicted_mean\"] = mean_pred\n",
    "df[\"soc_uncertainty\"] = std_pred\n",
    "\n",
    "# Convertir le DataFrame en Xarray pour l'affichage\n",
    "final_ds = df.set_index([\"y\", \"x\"]).to_xarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLOr2vFAavr6"
   },
   "source": [
    "**8. Visualisation Finale**\n",
    "\n",
    "Examinons notre résultat.\n",
    "\n",
    "**Gauche :** Notre nouvelle carte COS haute résolution (30m).\n",
    "\n",
    "**Droite :** Où le modèle est-il confus ? (Incertitude)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "75nAMYbJJJqF",
    "outputId": "d396e83d-02bd-4bcf-817a-16c6e85201eb"
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "# Afficher la Prédiction Moyenne\n",
    "final_ds[\"soc_predicted_mean\"].plot(ax=ax1, cmap=\"viridis\")\n",
    "ax1.set_title(\"Stock COS Prédit (0-5cm) [Rés. 30m]\")\n",
    "ax1.set_xlabel(\"Longitude\")\n",
    "ax1.set_ylabel(\"Latitude\")\n",
    "\n",
    "# Afficher l'Incertitude (Écart-Type)\n",
    "final_ds[\"soc_uncertainty\"].plot(ax=ax2, cmap=\"inferno\")\n",
    "ax2.set_title(\"Incertitude de Prédiction (É-T)\")\n",
    "ax2.set_xlabel(\"Longitude\")\n",
    "ax2.set_ylabel(\"Latitude\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzGJjQXga9pR"
   },
   "source": [
    "**Question de Discussion :**\n",
    "Observez la Carte d'Incertitude. Voyez-vous une incertitude plus élevée dans les montagnes (forte pente) ou dans les plaines agricoles plates ? Pourquoi le modèle pourrait-il avoir des difficultés dans ces zones ?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
